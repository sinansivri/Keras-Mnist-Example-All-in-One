{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 327s - loss: 0.4091 - acc: 0.8760 - val_loss: 0.1011 - val_acc: 0.9675\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 334s - loss: 0.1668 - acc: 0.9525 - val_loss: 0.0690 - val_acc: 0.9796\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 331s - loss: 0.1306 - acc: 0.9628 - val_loss: 0.0567 - val_acc: 0.9822\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 334s - loss: 0.1144 - acc: 0.9673 - val_loss: 0.0516 - val_acc: 0.9847\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 328s - loss: 0.1011 - acc: 0.9710 - val_loss: 0.0451 - val_acc: 0.9855\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 345s - loss: 0.0922 - acc: 0.9735 - val_loss: 0.0416 - val_acc: 0.9872\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 345s - loss: 0.0833 - acc: 0.9758 - val_loss: 0.0397 - val_acc: 0.9863\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 353s - loss: 0.0788 - acc: 0.9781 - val_loss: 0.0379 - val_acc: 0.9876\n",
      "Test loss: 0.0378735772568\n",
      "Test accuracy: 0.9876\n",
      "Saved trained model at C:\\Users\\Lenovo\\saved_models\\keras_mnist_trained_model.h5 \n"
     ]
    }
   ],
   "source": [
    "#Training a model with Keras-Tensorflow Backend\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 8\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))     # 1st Conv layer , 64 nodes , 3x3 kernel , image size 28x28 , relu activation\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))            # Resampling Layer image size 14x14\n",
    "model.add(Dropout(0.25))                             # Generalization Layer randomly shuts down 0.25 of nodes\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))              # 1st Fully connected layer , 64 nodes ,relu activation\n",
    "model.add(Dropout(0.5))                              # Generalization Layer randomly shuts down 0.50 of nodes\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))  # 2nd Fully connected Layer , 10 nodes for 10 classes,\n",
    "                                                     # softmax for probablity estimation\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_mnist_trained_model.h5'\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    \n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "print('Saved trained model at %s ' % model_path) # Save example code model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions from already trained model\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "#img=scipy.ndimage.imread(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\mnist_evaluate\\\\76.png\", flatten=True, mode=None)\n",
    "\n",
    "#im1=cv.LoadImage(\"C:\\Users\\Lenovo\\Desktop\\mnist_evaluate.jpg\")\n",
    "#path=('C:\\Users\\Lenovo\\Desktop\\mnist_evaluate\\76.png') .decode('unicode escape')\n",
    "\n",
    "img = Image.open( '2.png')\n",
    "grey=img.convert('L')\n",
    "grey.load()\n",
    "data = np.asarray( grey, dtype=\"float32\" );\n",
    "\n",
    "data = np.reshape(data, (1, 28, 28, 1));\n",
    "    \n",
    "\n",
    "model.predict(data,batch_size=1, verbose=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "Class Probabilities \n",
      "  [[  3.57606032e-37   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]] \n",
      " Prediction: [5]\n"
     ]
    }
   ],
   "source": [
    "# Load a model and prediction\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "model = load_model('keras_mnist_trained_model.h5')\n",
    "    \n",
    "img = Image.open( '2D.jpg')\n",
    "grey=img.convert('L')\n",
    "grey.load()\n",
    "data = np.asarray( grey, dtype=\"float32\" );\n",
    "\n",
    "data = np.reshape(data, (1, 28, 28, 1));\n",
    "\n",
    "\n",
    "\n",
    "a=model.predict(data) \n",
    "b=model.predict_classes(data)\n",
    "\n",
    "print (\"Class Probabilities \\n \",a,\"\\n Prediction:\",b)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 326s - loss: 0.4398 - acc: 0.8656 - val_loss: 0.0993 - val_acc: 0.9690\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 328s - loss: 0.1714 - acc: 0.9507 - val_loss: 0.0702 - val_acc: 0.9781\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 328s - loss: 0.1342 - acc: 0.9611 - val_loss: 0.0530 - val_acc: 0.9832\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 332s - loss: 0.1132 - acc: 0.9670 - val_loss: 0.0465 - val_acc: 0.9856\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 325s - loss: 0.0979 - acc: 0.9719 - val_loss: 0.0455 - val_acc: 0.9854\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 335s - loss: 0.0884 - acc: 0.9743 - val_loss: 0.0422 - val_acc: 0.9862\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 344s - loss: 0.0833 - acc: 0.9760 - val_loss: 0.0379 - val_acc: 0.9877\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 345s - loss: 0.0786 - acc: 0.9773 - val_loss: 0.0400 - val_acc: 0.9872\n",
      "Test loss: 0.0399546855015\n",
      "Test accuracy: 0.9872\n",
      "Saved trained model at C:\\Users\\Lenovo\\Desktop\\Mnist Working\\saved_models\\keras_mnist_trained_model_tb_trial.h5 \n"
     ]
    }
   ],
   "source": [
    "#Tensorboard trial\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "import os\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 8\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),             #1st Conv layer , 64 nodes , 3x3 kernel , image size 28x28 , relu activation\n",
    "                 activation='relu',                  \n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))     # 2nd Conv layer , 64 nodes , 3x3 kernel , image size 28x28 , relu activation\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))            # Resampling Layer image size 14x14\n",
    "model.add(Dropout(0.25))                             # Generalization Layer randomly shuts down 0.25 of nodes\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))              # 1st Fully connected layer , 64 nodes ,relu activation\n",
    "model.add(Dropout(0.5))                              # Generalization Layer randomly shuts down 0.50 of nodes\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))  # 2nd Fully connected Layer , 10 nodes for 10 classes,\n",
    "                                                     # softmax for probablity estimation\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[tensorboard])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_mnist_trained_model_tb_trial.h5'\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    \n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "\n",
    "print('Saved trained model at %s ' % model_path) # Save example code model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neuralnets]",
   "language": "python",
   "name": "conda-env-neuralnets-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
